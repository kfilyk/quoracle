# -*- coding: utf-8 -*-
"""returns.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17nZcmme0IMzrFLiJjP1f7hpMc4iC03AE

This code prints to a file: a list of daily close, returns values for a number of stock indices
"""

import cpi
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
import csv
import math
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
import yfinance as yf
#!pip install yfinance
#!pip install - q pyyaml h5py  # Required to save models in HDF5 format
#!pip install cpi

cpi.update()

#from google.colab import drive
# drive.mount('/content/drive')

# allows us to see everything
pd.set_option('display.max_columns', None)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('max_colwidth', None)


def combine_histories(stock_dfs):
    # This function combines multiple stock dfs and sorts them by date
    combine_df = None

    for key in stock_dfs:
        # print(key)
        if combine_df is not None:
            combine_df = pd.concat([combine_df, stock_dfs[key]])
        else:
            combine_df = stock_dfs[key]  # get the first one

    combine_df.sort_values(by=['Date'], inplace=True)
    return combine_df

# extract all data from yf. stock that can be appended to full array


def prep_lstm_stock(stock_df, name):
    nan_idxs = stock_df.isnull().any(1).to_numpy().nonzero()[0]
    # print("Rows with NaN: ", nan_idxs) # bool
    for i in nan_idxs:  # list of row indices
        # print(stock_df.iloc[i])
        nan_close = stock_df.iloc[i-1, 'Close']
        stock_df.iloc[i] = {'Open': nan_close, 'Close': nan_close,
                            'High': nan_close, 'Low': nan_close, 'Volume': 0}
    stock_df['Close'] = stock_df.apply(lambda x: cpi.inflate(
        x['Close'], x.name.year) if x.name.year < 2019 else x['Close'], axis=1)  # adjust for inflation
    stock_df['Stock'] = pd.DataFrame(index=stock_df.index, columns=['Stock']).fillna(
        name)  # place this stock name as an column
    stock_df['Return'] = (stock_df['Close'] - stock_df['Close'].shift(
        1, fill_value=0)) / stock_df['Close'].shift(1, fill_value=1)  # get return
    stock_df['Return'].iloc[0] = 0  # change first gradient value to 0
    stock_df['Std Return'] = (stock_df['Return']-stock_df['Return'].mean()) / \
        stock_df['Return'].std()  # using standardization
    stock_df = stock_df.drop(['High', 'Low', 'Open', 'Stock Splits', 'Dividends',
                             'Return', 'Volume'], axis=1, errors='ignore')  # drop these for now

    # LEAVE THIS: deletes september 11th 2001 from data
    stock_df = stock_df[stock_df.index != '2001-09-12']

    idx = pd.date_range(
        stock_df.index[0], stock_df.index[-1], freq='B').rename('Date')
    # should fill in all missing weekdays
    stock_df = stock_df.reindex(idx, fill_value=np.NaN)
    stock_df['Close'] = stock_df['Close'].ffill()
    stock_df['Stock'] = stock_df['Stock'].ffill()
    stock_df['Std Return'] = stock_df['Std Return'].fillna(0)

    # now get all stocks where Stock = 0

    # if name=="KO":
    #print("STOCK DF %s\n %s" % (name, stock_df.tail(100)))
    # Working up to here
    #pd.set_option("display.max_rows", None, "display.max_columns", None)
    return stock_df


# example of returned data
test_stock = prep_lstm_stock(yf.Ticker('JNJ').history(period='max'), 'JNJ')
# check period around 9/11: labour day should be ffilled, as should the week of the attacks
print(test_stock.loc['2001-08-28':'2001-09-30'])

# print(test_stock.head(20))
# print(test_stock.tail(20))

stock_list = []
#stock_list = ['AMZN','AAPL', 'FB', 'MSFT','TSLA', 'GOOG']
# stock_list = ['KO','AMZN', 'AAPL', 'FB','GOOGL', 'MSFT', 'TSLA', 'XOM', 'GE', 'IBM', 'MO', 'JNJ','GM', 'CVX','WMT', 'PG', 'BRK-A', 'BRK-B', '^VIX', 'WFC'] #'DWDP' delisted?
with open('../data/stock_list.csv', 'r') as f:
    for r in f:
        stock_list.append(r.rstrip())

print(stock_list)
#stock_list = ['KO','AMZN', 'AAPL', 'FB','GOOGL', 'MSFT', 'TSLA', 'XOM', 'GE', 'IBM', 'MO', 'JNJ','GM', 'CVX','WMT', 'PG', 'BRK-A', 'BRK-B', '^VIX', 'WFC', 'DD', 'MRK', 'INTC', 'JPM', 'HD', 'PEP','PCG', 'FSLR', 'MUR', 'MOS', 'DVN', 'MRO', 'FLR', 'EQT', 'RRC', 'RIG', 'CHK', 'DPZ', 'ULTA', 'SLV', 'GME', 'AMC', '^VXN', '^DJI','^IXIC']
# including best and worst stocks from 11 years: https://www.kiplinger.com/slideshow/investing/t052-s001-11-best-and-11-worst-stocks-11-year-bull-market/index.html
stock_dfs = {}  # get stocks from yf and store prepped version
for stock in stock_list:
    stock_dfs[stock] = prep_lstm_stock(
        yf.Ticker(stock).history(period='max'), stock)

cumulative_df = combine_histories(stock_dfs)

# what we want is, for every new stock(s) added to dataset, create a history that spans the entire stock history.
# AAPL joins in 1980: we get a stock history dataset that contains all stocks being tracked from period 1980-2021
# count the number of stocks active at any given date; use this to partition into histories
stocks_per_date = pd.DataFrame(
    cumulative_df.index.value_counts(), columns=["Date"])
cumulative_df = cumulative_df.join(stocks_per_date)
# print(cumulative_df.loc[cumulative_df['Date']==10].head(30))

# print(cumulative_df.loc[cumulative_df['Date']==10].loc['1962-01-15'])

# print(cumulative_df.head(20))
# print(cumulative_df.tail(20))

# We have to combine multiple keras models. one for each section of stock history that contains n stocks. starting at the beginning with a single stock, group model training sets by
# a partition of the cumulative histories of all tradable stocks during a timespan (ex. starting with  AAPL from 1980-1986)
stock_history_dfs = {}
num_stocks_in_history = {}
partitions = np.sort(cumulative_df['Date'].unique())
print("PARTITIONS: ", partitions)

# need to sort in order of stock addition
unique_stocks_ordered = []  # dicts are ordered in python3

i = 1
for p in partitions:
    # get one of the history partitions (ex. 2012-2021)
    hist = cumulative_df.loc[cumulative_df['Date'] == p].dropna()
    if not hist.empty:  # if the history not empty
        unique_stocks = list(hist['Stock'].unique())
        #print("UNIQUE STOCKS: ", unique_stocks)
        for u in unique_stocks:
            if u not in unique_stocks_ordered:
                unique_stocks_ordered.append(u)
        #print("UNIQUE STOCKS ORDERED: ", unique_stocks_ordered)
        stock_history = pd.DataFrame(index=cumulative_df.index.unique())
        #print("EMPTY STOCK HISTORY:", stock_history)
        for u in unique_stocks_ordered:
            # collect the columns of cumulative_df pertaining to stock
            s = cumulative_df.loc[cumulative_df['Stock'] == u]
            # print(s.head())
            s = s.add_suffix("_"+u)
            s = s.drop(["Stock_"+u, "Date_"+u], axis=1)
            stock_history = stock_history.join(s)
            # print(stock_history)
        stock_history_dfs[i] = stock_history.dropna()  # get rid of NA samples
        num_stocks_in_history[i] = len(unique_stocks_ordered)
        print("TIMESPAN %d: (%s to %s) (%d STOCKS, %d SAMPLES, %d DATES): %s" % (i, hist.index.min(), hist.index.max(
        ), num_stocks_in_history[i], hist.shape[0], len(hist.index.unique()), unique_stocks_ordered))
        i = i+1

# get a list of all column names - should be 5 features per stock
print(stock_history_dfs[30].head())
